import json
import asyncio
import redis
import logging
import sqlite3
import os
import sys
import re

project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)
from crypto_analysis.crypto_analyzer import CryptoAnalyzer

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger(__name__)

class NewsConsumer:
    def __init__(self, redis_config, db_path="history.db"):
        self.redis_client = redis.Redis(host=redis_config["host"], port=redis_config["port"], decode_responses=True)
        self.list_key = redis_config["stream_key"]
        # æ–°å¢:è¿æ¥æ•°æ®åº“
        self.conn = sqlite3.connect(db_path)
        self.cursor = self.conn.cursor()
        self.db_path = db_path
        # æ–°å¢:åˆ›å»ºè¡¨(å¦‚ä¸å­˜åœ¨)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS messages (
            id INTEGER PRIMARY KEY,
            channel_id TEXT,
            message_id INTEGER,
            text TEXT,
            date TEXT,
            keywords TEXT,
            industry TEXT
            )
        """)
        self.conn.commit()

        self.analyzer = CryptoAnalyzer()
        # âœ… CryptoAnalyzer å·²åŒ…å« KeyBERTã€spaCyã€å¸ç§è¯†åˆ«ç­‰æ‰€æœ‰åˆ†æåŠŸèƒ½
        
    async def process_message(self, message):
        """å¤„ç†å•æ¡æ¶ˆæ¯ï¼Œæ‰“å°å¹¶å†™å…¥æ•°æ®åº“ï¼Œæ—¢è¯†åˆ«å¸ç§ï¼Œä¹Ÿæå–å…³é”®è¯"""
        data = json.loads(message)
        logger.info(f"Channel: {data['channel']}")
        logger.info(f"Time: {data['timestamp']}")
        logger.info(f"Content: {data['content']}")
        logger.info("-" * 50)
        data = self.news_preprocess(data)

        # è¯†åˆ«å¸ç§
        # mentioned_coins = self.identify_currency(data['content'])
        mentioned_coins = self.analyzer.identify_currency(data['content'])
        coins_str = ",".join(mentioned_coins)
        print("Mentioned Currencies: ", coins_str)

        # æå–å…³é”®è¯
        # keywords_str = self.run_keywords_extraction(data['content'])
        keywords = self.analyzer.extract_keywords(
            data['content'],
            top_n=10
        )
        print("Keywords: ", keywords)
        if keywords:
            keywords_str = ",".join([kw[0] for kw in keywords])
            # keywords_str = self.capitalize_english(keywords_str)  # è‹±æ–‡éƒ¨åˆ†è½¬å¤§å†™
        else:
            keywords_str = ""

        try:
            self.cursor.execute("SELECT MAX(message_id) FROM messages")
            result = self.cursor.fetchone()
            next_message_id = (result[0] or 0) + 1
            self.cursor.execute(
                "INSERT OR IGNORE INTO messages (id, channel_id, message_id, text, date, keywords, industry) VALUES (?, ?, ?, ?, ?, ?, ?)",
                (data['id'], data['channel'], next_message_id, data['content'], data['timestamp'], keywords_str, coins_str)
            )
            self.conn.commit()
        except Exception as e:
            logger.error(f"DB insert error: {e}")

    def capitalize_english(self, text: str) -> str:
        """å°†å­—ç¬¦ä¸²ä¸­çš„è‹±æ–‡éƒ¨åˆ†è½¬ä¸ºå¤§å†™ï¼Œä¿ç•™ä¸­æ–‡å’Œå…¶ä»–å­—ç¬¦ä¸å˜"""
        result = []
        for char in text:
            if char.isalpha() and ord(char) < 128:  # ASCII è‹±æ–‡å­—ç¬¦
                result.append(char.upper())
            else:
                result.append(char)
        return ''.join(result)

    def news_preprocess(self, data):
        content = data['content']
        def clean_text(text):
            # åˆ é™¤é™¤äº†å­—æ¯ä¹‹é—´ä»¥å¤–çš„æ‰€æœ‰ç©ºæ ¼
            text = re.sub(r'(?<![a-zA-Z]) | (?![a-zA-Z])', '', text)
            # å»æ‰æ‰€æœ‰ç©ºè¡Œ,æ·»åŠ ä¸€ä¸ªç©ºæ ¼
            text = re.sub(r'\n+', ' ', text).strip()
            return text
        content = clean_text(content)

        if data['channel'] == '-1001387109317':# @theblockbeats
            content = re.sub(r'BlockBeatsæ¶ˆæ¯ï¼Œ', '', content)
            content = re.sub(r'^åŸæ–‡é“¾æ¥\s*\[.*?\]\(.*?\)\s*$', '', content, count=0, flags=re.M)

        if data['channel'] == '-1001735732363':# @TechFlowDaily
            content = re.sub(r'https?://\S+', '', content)
            content = re.sub(r'æ·±æ½®TechFlowæ¶ˆæ¯ï¼Œ', '', content)

        if data['channel'] == '-1002395608815':# @news6551
            pattern = r'----------.*|ğŸ“¢'
            content = re.sub(pattern, '', content, flags=re.DOTALL)

        if data['channel'] == '-1002117032512':# @MMSnews
            pattern = r'https://[^\s]+|ğŸ“'
            content = re.sub(pattern, '', content)

        data['content'] = content
        return data

    def __del__(self):
        self.conn.close()

    async def run_history_mode(self):
        """å†å²æ¨¡å¼ï¼šä»å¤´å¼€å§‹è¯»å–æ‰€æœ‰æ¶ˆæ¯"""
        # è·å–æ‰€æœ‰æ¶ˆæ¯
        messages = self.redis_client.lrange(self.list_key, 0, -1)
        for message in messages:
            await self.process_message(message)
        # è¿è¡Œåˆ†æ
        await self.analyzer.run_analysis(self.db_path)

    async def run_stream_mode(self):
        """å®æ—¶æ¨¡å¼ï¼šæŒç»­ç›‘å¬æ–°æ¶ˆæ¯"""
        last_id = 0  # ç”¨äºè®°å½•ä¸Šæ¬¡å¤„ç†çš„ä½ç½®

        while True:
            try:
                # è·å–æ–°æ¶ˆæ¯ï¼ˆä½¿ç”¨é˜»å¡æ“ä½œï¼‰
                result = self.redis_client.brpop(self.list_key, timeout=1)

                if result:
                    _, message = result
                    await self.process_message(message)
                else:
                    # æ— æ–°æ¶ˆæ¯ï¼Œç­‰å¾…ä¸€ä¸‹
                    await asyncio.sleep(1)

            except Exception as e:
                logger.info(f"Error processing message: {e}")
                await asyncio.sleep(1)  # å‡ºé”™æ—¶æš‚åœä¸€ä¸‹
